# parameter_lr_wd_tuning

## 问题分析
多模态大模型涉及多种模态融合，例如VLM模型包含视觉编码器、语言解码器等多类模块，不同模块（如视觉特征提取层、语言注意力层、偏置/归一化层）对学习率（LR）和权重衰减（WD）的敏感度存在差异。全局统一的LR/WD配置无法适配各模块的差异化优化需求，可能导致部分模块欠拟合或过拟合，影响模型多模态对齐效果和最终模型性能。

## 解决方案
新增参数名关键词驱动的LR缩放与WD排除功能：
1. 支持通过关键词匹配参数名，对指定参数排除权重衰减，避免特定等参数因WD导致的优化偏差；
2. 支持通过关键词匹配参数名，对指定参数（如VLM的视觉模块）应用自定义LR乘数，实现精细化的参数级学习率调控；
3. 所有匹配逻辑采用大小写不敏感的字符串匹配

## 使用方法

上述特性默认关闭，如需启用，在模型启动shell训练脚本中添加如下参数（以下仅做配置方式展示，需根据实际需要修改）：

   ```shell
   GPT_ARGS="
       ...
       --weight-decay-exclude-modules norm bias \ # 排除指定参数的权重衰减，根据实际需要设置参数关键词
       --lr-scale-modules vision \  # 对视觉模块参数缩放学习率（如mult=0.5）
       --lr-mult 0.5 \
   "
   ```